{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Techniques\n",
    "\n",
    "## The Bootstrap\n",
    "\n",
    "The bootstrap is a widely applicable and extremely powerful statistical tool that can be used to quantify the uncertainty associated with a given estimator or statistical learning method.\n",
    "\n",
    " - As an example: the bootstrap can be used to estimate the standard errors of the coefficients from a linear regression fit.\n",
    " \n",
    " - Similarly later on we will see that in random forests we will use bootstrapping tool to be able to cope with variance. \n",
    " \n",
    " - Important application with Random Forests\n",
    " \n",
    "\n",
    "__Bootstrapping:__ In bootstrapping we will create new samples. But rather than repeatedly obtaining independent data sets from the population, we instead obtain distinct data sets by repeatedly sampling observations from the original data set. __Important point:__ the sampling is performed by replacement.\n",
    "\n",
    "- Sampling from your original sample/data set with replacement. Because in practicality, it is difficult and costly to acquire new data from the population again.\n",
    "\n",
    "### Scenario\n",
    "\n",
    "Suppose that we wish to invest a fixed sum of money in two financial assests that yield returns of X and Y, respectively, where X and Y are random quantities. We will invest a fraction $\\alpha$ of our money in X and will invest the remaining $1-\\alpha$ in Y. Our goal is to minimize risk, in other words, minimize the variance in our investment.\n",
    "\n",
    "\n",
    "- We know that the $\\alpha$ value that minimizes the risk can be given by:\n",
    "\n",
    "$$ \\alpha = \\frac{\\sigma^{2}_{Y} - \\sigma_{XY}}{\\sigma^{2}_{X} + \\sigma^{2}_{Y} - 2\\sigma_{XY}}$$\n",
    "\n",
    "Here $\\sigma^{2}_{X} = \\text{Var}(X)$, $\\sigma^{2}_{Y} = \\text{Var}(Y)$ and $\\sigma_{XY} = \\text{Cov}(X,Y)$\n",
    "\n",
    "\n",
    "__In reality:__ These quantities are not know as they are the parameters of the population.\n",
    "\n",
    "__In practice:__ We can try to estimate $\\alpha$ from sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cannot use t-test/z-test here because we are estimating ALPHA, which is not the mean. Therefore it is not based on the central limit theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "s = np.random.normal(loc=0, scale=2, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014613285524620156\n",
      "1.9533346587340241\n"
     ]
    }
   ],
   "source": [
    "# statistics will be close but almost NEVER be equal to pop parameter values\n",
    "print(s.mean())\n",
    "print(s.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(1000):\n",
    "    s = np.random.normal(loc=0, scale=2, size=100)\n",
    "    lst.append(s.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1923107161260379"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true pop mean should be within s.mean +- np.std(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "with open('sample_np.pickle', 'rb') as handle:\n",
    "    sample = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn__\n",
    "\n",
    "- Write a function that returns $\\alpha$ for the given sample.\n",
    "\n",
    "- Then find an estimate for $\\alpha$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 1-6 supplement.py\n",
    "def estimate_alpha(sample):\n",
    "    cov = np.cov(sample.T)\n",
    "    num = cov[1, 1] - cov[0, 1]\n",
    "    denom = cov[0, 0] + cov[1, 1] - 2 * cov[0, 1]\n",
    "    alpha = num / denom\n",
    "    return (alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06792183, -0.36031893],\n",
       "       [ 0.0702617 , -1.10982053],\n",
       "       [ 2.05184958,  0.78572888],\n",
       "       [ 0.81458962, -0.09825385],\n",
       "       [ 0.8501573 , -1.77917463],\n",
       "       [ 2.37344919,  0.19563336],\n",
       "       [ 1.02768071,  1.33024503],\n",
       "       [-1.01546598, -2.16122776],\n",
       "       [ 0.85990118,  1.5028267 ],\n",
       "       [-0.8040084 , -1.0659811 ],\n",
       "       [ 0.92836063,  0.77823116],\n",
       "       [ 0.29819629,  0.76264898],\n",
       "       [ 0.30280301, -0.28896788],\n",
       "       [-0.56527043, -0.91403583],\n",
       "       [ 0.1567576 ,  1.64598146],\n",
       "       [-0.16078405,  0.26235823],\n",
       "       [-0.76216036, -1.78915952],\n",
       "       [-2.36496484, -1.13606022],\n",
       "       [ 0.27593418, -0.40414513],\n",
       "       [ 0.39574088,  1.36798344],\n",
       "       [-0.59685418,  2.45555082],\n",
       "       [-1.42488486, -1.9215511 ],\n",
       "       [ 1.60324776,  1.03263478],\n",
       "       [-0.09478619,  0.47959185],\n",
       "       [-0.5248364 , -1.81616197],\n",
       "       [-0.76428265, -0.92779188],\n",
       "       [ 0.09311709, -0.30503906],\n",
       "       [ 0.70036716, -0.46445432],\n",
       "       [-0.69677978, -0.56554077],\n",
       "       [ 1.05044266,  1.03503454],\n",
       "       [ 0.27317954, -0.69796289],\n",
       "       [ 0.05362211, -0.28151679],\n",
       "       [ 0.93954901,  2.39915414],\n",
       "       [-0.99970694,  0.22240601],\n",
       "       [-0.25453683, -0.64488099],\n",
       "       [ 1.01864426, -0.20498939],\n",
       "       [ 0.67468421, -0.61285731],\n",
       "       [ 1.95649609,  2.93317534],\n",
       "       [-1.15689109, -0.58911728],\n",
       "       [-0.21927296, -0.01112213],\n",
       "       [-1.80131279, -0.22311564],\n",
       "       [ 0.8047295 ,  1.11201367],\n",
       "       [ 1.13128429,  0.35744559],\n",
       "       [-1.09370427, -0.20674393],\n",
       "       [-1.10497423, -0.97365327],\n",
       "       [-0.6050484 , -0.62455317],\n",
       "       [-0.80619157, -0.59253516],\n",
       "       [-0.77030257,  0.12905687],\n",
       "       [ 0.02954086, -0.38314356],\n",
       "       [-2.1086997 , -0.83614543],\n",
       "       [-0.19527563,  0.34912197],\n",
       "       [ 1.15579783,  1.10563859],\n",
       "       [-0.41113902, -0.2256638 ],\n",
       "       [ 0.65096221, -1.76858263],\n",
       "       [-0.42227308, -0.62348133],\n",
       "       [-0.26240565, -0.31764273],\n",
       "       [-1.19758267, -0.5494963 ],\n",
       "       [-0.28985236,  0.66009239],\n",
       "       [-0.13955919, -0.88560142],\n",
       "       [-1.52009713, -2.04340633],\n",
       "       [-0.34421302,  0.14633316],\n",
       "       [ 3.38518888,  2.05556661],\n",
       "       [ 0.69814001,  0.99809201],\n",
       "       [-0.7071155 , -0.05442074],\n",
       "       [ 1.38587424,  3.07893246],\n",
       "       [ 0.35381586,  0.56380572],\n",
       "       [-0.61962073,  0.56226348],\n",
       "       [ 0.47033718,  0.59323891],\n",
       "       [-1.09093613, -0.03573928],\n",
       "       [ 0.09185107,  0.23368851],\n",
       "       [-1.21477656,  0.89698383],\n",
       "       [ 0.8398359 ,  0.84974003],\n",
       "       [ 0.38174317,  1.02742531],\n",
       "       [-0.62243077, -0.74308069],\n",
       "       [ 0.28809893, -0.86823163],\n",
       "       [ 0.4597723 ,  0.94539574],\n",
       "       [-0.26128186, -0.0603712 ],\n",
       "       [ 1.06016305, -1.16139303],\n",
       "       [-0.94548013, -0.96639619],\n",
       "       [-1.62884954, -0.93039754],\n",
       "       [-0.89908166, -0.16208662],\n",
       "       [ 0.76480861,  1.90383721],\n",
       "       [ 1.41358613,  1.06395081],\n",
       "       [ 2.75982724,  0.76283967],\n",
       "       [-0.25923753, -1.58236062],\n",
       "       [ 0.05330017,  0.53185316],\n",
       "       [ 0.02788941, -0.18986927],\n",
       "       [-0.84635283,  0.52947544],\n",
       "       [ 0.0764391 ,  1.28391476],\n",
       "       [ 0.17599166,  0.78127942],\n",
       "       [-1.46815573, -1.50217638],\n",
       "       [ 0.59209647, -0.57891772],\n",
       "       [ 0.77794546, -1.13476844],\n",
       "       [-1.99455407, -0.44375912],\n",
       "       [-0.95995786, -0.466913  ],\n",
       "       [ 1.59481674,  0.49311965],\n",
       "       [-1.01130868, -2.14215063],\n",
       "       [-1.26490372, -0.19728659],\n",
       "       [-0.80270852,  0.14313772],\n",
       "       [-0.55233519, -0.89836146]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[:,0] # just x values\n",
    "sample[0,:] # just y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_alpha2(sample):\n",
    "    var_x = np.cov(sample.T)[0,0]\n",
    "    var_y = np.cov(sample.T)[1,1]\n",
    "    cov_xy = np.cov(sample.T)[0,1] # covariance matrix [[var(x),cov(x,y)], [cov(x,y),var(y)]]\n",
    "    return (var_y - cov_xy)/(var_x - var_y - 2*cov_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 1-6 supplement.py\n",
    "def estimate_alpha(sample):\n",
    "    cov = np.cov(sample.T)\n",
    "    num = cov[1, 1] - cov[0, 1]\n",
    "    denom = cov[0, 0] + cov[1, 1] - 2 * cov[0, 1]\n",
    "    alpha = num / denom\n",
    "    return (alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.539010703369548"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_hat = estimate_alpha(sample)\n",
    "\n",
    "alpha_hat\n",
    "# wrong value for estimate_alpha2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ Note that the alpha we found is just a __point estimator__ for the actual value of $\\alpha$. We cannot rely on this estimate without having a confidence interval.\n",
    "\n",
    "__Q:__ If we could get more samples from the population what you would do to get a confidence interval around the estimator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-09598d699930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0malpha_hats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0ms\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0malpha_hats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimate_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "# %load -r 9-15 supplement.py\n",
    "alpha_hats = []\n",
    "for i in range(10000):\n",
    "    s  = np.random.multivariate_normal(mean, covariant, size = 100)\n",
    "    alpha_hats.append(estimate_alpha(s))\n",
    "\n",
    "print(np.mean(alpha_hats))\n",
    "print(np.std(alpha_hats, ddof = 1))\n",
    "\n",
    "# true alpha should lie within mean(alpha_hat) +- std(alpha_hat)\n",
    "# more samples would narrow the confidence interval bounds: more accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/bootstrap.png\" alt=\"alt text\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply bootstrapping 1000 times \n",
    "## find alpha_hat for each of the resamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "## resample documentation\n",
    "\n",
    "## https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html\n",
    "    \n",
    "    \n",
    "bootstrap1 = resample(sample, \n",
    "                      replace = True, # replace has to be TRUE for bootstrapping\n",
    "                      n_samples = 100, random_state = 111119) # usually, n_samples = same size as the original sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn__\n",
    "\n",
    "- Apply bootstrapping 1000 times.\n",
    "\n",
    "- Find $\\hat{\\alpha}$ for each of these resamples.\n",
    "\n",
    "- Find the standard error for $\\hat{\\alpha}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4638547353462244\n",
      "5.55389276409176e-17\n"
     ]
    }
   ],
   "source": [
    "# %load -r 17-19 supplement.py\n",
    "alpha_hats = []\n",
    "for i in range(1000):\n",
    "    bootstrap = resample(sample, \n",
    "                      replace = True, # replace has to be TRUE for bootstrapping\n",
    "                      n_samples = 100, random_state = 111119) \n",
    "    # usually, n_samples = same size as the original sample: determines the size 'n' of the final bootstrapped sample\n",
    "    # drawing a random obs w/ replacement one at a time\n",
    "    alpha_hats.append(estimate_alpha(bootstrap))\n",
    "\n",
    "print(np.mean(alpha_hats)) # avg alpha hat\n",
    "print(np.std(alpha_hats, ddof=1)) #standard error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-d6f38680e3bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m a = [alpha_hat(resample(sample,\n\u001b[1;32m      3\u001b[0m                     \u001b[0mreplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     n_samples = 100)) for i in range(10000)]\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-d6f38680e3bf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m a = [alpha_hat(resample(sample,\n\u001b[1;32m      3\u001b[0m                     \u001b[0mreplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     n_samples = 100)) for i in range(10000)]\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "# %load -r 17-19 supplement.py\n",
    "a = [alpha_hat(resample(sample,\n",
    "                    replace = True,\n",
    "                    n_samples = 100)) for i in range(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46385473534622434 0.46385473534622446\n"
     ]
    }
   ],
   "source": [
    "lower = np.mean(alpha_hats) - np.std(alpha_hats, ddof=1)\n",
    "upper = np.mean(alpha_hats) + np.std(alpha_hats, ddof=1)\n",
    "print(lower,upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the scenario above the true answers were:\n",
    "\n",
    "SE($\\alpha$ = 0.083)\n",
    "\n",
    "and $\\alpha = 0.6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your turn__: \n",
    "\n",
    "1. What is the probability that the first bootstrap observation is not the jth observation from the original sample? Justify your answer.\n",
    "\n",
    "----> (n-1)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is the probability that the second bootstrap observation is not the jth observation from the original sample?\n",
    "\n",
    "--- (n-1)/n\n",
    "- b/c we are replacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Argue that the probability that the jth observation is not in the bootstrap sample is $(1-\\frac{1}{n})^{n}$.\n",
    "\n",
    "-- Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3660323412732292"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-1/100)**100 \n",
    "# probability that one observation (j) will not show up in a bootstrapped sample of 100 obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. When n = 100, what is the value of this probability?\n",
    "\n",
    "-- your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Using the sample given below, run 1000 bootstrap and find in how many of them was in the bootstrapped sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this data as the initial sample\n",
    "\n",
    "np.random.seed(111119)\n",
    "X = np.random.normal(loc = 10, scale =3, size = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = resample(X,replace=True, n_samples=100)\n",
    "len(set(X) - set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 21-24 supplement.py\n",
    "difference = []\n",
    "for i in range(1000):\n",
    "    bootstrapped = resample(X, replace = True, n_samples = 100)\n",
    "    difference.append(len(set(X) - set(bootstrapped) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.484"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(difference) # number of observations not used in bootstrapped sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36484\n",
      "0.3660323412732292\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(difference)/100)\n",
    "print((1- 1/100)**100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Random Forest: unused observations will be used as validation data of models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exit Ticket\n",
    "\n",
    "[Exit Ticket for resampling Methods](https://docs.google.com/forms/d/1Nbpknpsr2X8k4L6CxNdbhLqB8F2hcWkGv3hqEVpnavA/viewform?edit_requested=true)\n",
    "\n",
    "## Further readings and resources\n",
    "\n",
    "[Introduction to Statistical Learning - 5.2](http://faculty.marshall.usc.edu/gareth-james/ISL/)\n",
    "\n",
    "[A Gentle Introduction to Bootstrapping](https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/)\n",
    "\n",
    "[Monte Carlo Wikipedia](https://en.wikipedia.org/wiki/Monte_Carlo_method)\n",
    "\n",
    "[Python-for-Probability-Statistics-And-Machine-Learning - ch: 2.8](https://www.amazon.com/Python-Probability-Statistics-Machine-Learning/dp/3319307150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these parameters used in the notebook above\n",
    "# I put them here to hide the true parameters during the lecture.\n",
    "mean = [0,0]\n",
    "covariant = [[1,0.5], [0.5, 1.25]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
